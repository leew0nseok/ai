{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "input_path = './archive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = { # 데이터 전처리 파이프라인을 정의한 딕셔너리입니다. \n",
    "    'train' :  # 이 파이프라인은 'train' 데이터와 'validation' 데이터를 위한 전처리 단계를 각각 정의합니다.\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomAffine(0, shear = 10, scale = (0.8, 1.2)), # 이미지에 무작위 어파인 변환(회전, 이동, 크기 조절)을 적용합니다.\n",
    "        transforms.RandomHorizontalFlip(), # 이미지를 무작위로 수평으로 뒤집습니다.\n",
    "        transforms.ToTensor(), # 이미지를 PyTorch 텐서 형식으로 변환합니다.\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation' :\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train' :\n",
    "    datasets.ImageFolder(input_path + 'training_set/training_set', data_transforms['train']),\n",
    "    'validation' : \n",
    "    datasets.ImageFolder(input_path + 'test_set/test_set', data_transforms['validation'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train' :\n",
    "    torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                batch_size = 32,\n",
    "                                shuffle = True,\n",
    "                                num_workers = 0),\n",
    "    'validation' :\n",
    "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
    "                                batch_size = 32,\n",
    "                                shuffle = False,\n",
    "                                num_workers = 0)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leewonseok/anaconda3/envs/nlp/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/leewonseok/anaconda3/envs/nlp/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/leewonseok/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 64.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 128),\n",
    "    nn.ReLU(inplace = True),\n",
    "    nn.Linear(128, 2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs = 3):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, lavels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = lavels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n",
      "train loss: 0.1414, acc: 0.9405\n",
      "Epoch 2/3\n",
      "----------\n",
      "train loss: 0.0724, acc: 0.9736\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_trained = train_model(model,criterion, optimizer, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models\n",
    "!mkdir models/pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trained.state_dict(), 'models/pythorch/weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying last Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained = False).to(device)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 128),\n",
    "    nn.ReLU(inplace = True),\n",
    "    nn.Linear(128, 2)).to(device)\n",
    "model.load_state_dict(torch.load('modles/pytorch/weights.h5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing some sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_img_paths = ['test_set/test_set/cats/cat.4001.jpg',\n",
    "                        'test_set/test_set/cats/cat.4003.jpg',\n",
    "                        'test_set/test_set/cats/dog.4004.jpg',\n",
    "                        'test_set/test_set/cats/dog.4006.jpg']\n",
    "img_list = [Image.open(input_path + img_path) for img_path in validation_img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
